---
title: "Obrada podataka"
author:
  name: Luka Sikic, PhD
  affiliation: Fakultet hrvatskih studija | [OP](https://lusiki.github.io/WebObradaPodataka/)
subtitle: 'Predavanje 6: Preuzimanje podataka sa interneta (Webscraping I)'
output:
  html_document:
    theme: flatly
    highlight: haddock
    toc: yes
    toc_depth: 4
    toc_float: yes
    keep_md: yes
  pdf_document:
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, dpi=300)
```

## Software podrška 

### *Eksterni* software

Za današnje pedavanje je potrebno instaliriati [SelectorGadget](https://selectorgadget.com/) (Instalacija je moguća preko [linka](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb).). SelectorGadget je Chrome ekstenzija koja omogućava jednostavno pronalaženje [CSS selektora](https://devhints.io/css) na web stranicama.  SelectorGadget je dostupan isključivo za Chrome. U slučaju da više volite Firefox, alternativa je [ScrapeMate](https://addons.mozilla.org/en-US/firefox/addon/scrapemate/).

### R paketi 

- Novi: **rvest**, **janitor**
- Korišteni u prethodnim predavanjima: **tidyverse**, **lubridate**, **hrbrthemes**

Prisjetite se da je **rvest** automatski instaliran sa *tidyverse* paketom. Ipak, ovo je prigodan način da instalirate i učitate sve prethodno pobrojane pakete ukoliko to niste već napravili: 

```{r libs, cache=F, message=F, warning=F}
## učitaj i instaliraj pakete
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, rvest, lubridate, janitor, hrbrthemes)
## ggplot2 tema (po želji)
theme_set(hrbrthemes::theme_ipsum())
```

## Webscraping osnove

Ovo predavanje se bavi preuzimanjem sadržaja sa web-a na vaše lokalno računalo. Svi već imamo iskustvo sa pregledom web sadržaja u browser-u (Chrome, Firefox,...) pa je vjerojatno logično da sadržaj koji gledamo negdje mora postojati u podatkovnom obliku. Važno je razumjeti da postoje dva osnovna načina na koja se web sadržaj prikazuje (*engl.render*) u browser-u:

1. na strani servera (*Server-side*)
<br>
2. na strani klijenta (*Client side*)

[Ovdje](https://www.codeconquest.com/website/client-side-vs-server-side/) pogledajte ako vas zanima više detalja (uključujući primjere).
<br>
Za potrebe ovog predavanja, glavni su sljedeći elementi: 



### 1. Server-strana

- Skripte koje čine web stranicu se ne izvršavaju na lokalnom računalu nego na *host* serveru koji "emitira" sav HTML kod. 
  - npr. Wikipedia tablice su već popupunjene sa svim informacijama (brojevi, datumi, nazivi...) koje vidimo u browser-u. 
- Drugačije rečeno, sve informacije koje vidimo u našem browser-u su već procesuirane od strane *host* servera. 
- Zamislite to kao da su informacije ugrađene u HTML web stranice.
- **Izazov za Webscraping:** Pronaći odgovarajuće CSS (ili Xpath) selektore. Snalaženje u dinamičkim web stranicama (npr. "Next page" i "Show More" tabovi).
- **Ključni koncepti:** CSS, Xpath, HTML
  
### 2. Client-strana
- Web stranica sadržava "prazni" HTML ili CSS okvir.  
  - Npr. Moguće je da se stranica sastoji od praznog predloška tablice bez ikakvih vrijednosti.
- Kada posjetimo URL takve web stranice, naš browser šalje zahtijev (*request*) na host server.
- U slučaju da je sve u redu sa zahtjevom (*valid request*), server šalje odgovor (*response*) kao skriptu (*script*) koju naš browser izivršava i koristi kako bi popunio HTML predložak sa (specifičnim) informacijama koje smo zatražili.
- **Izazov za Webscraping:** Pronaći "API točke" može biti problematično pošto one nisu uvijek direktno vidljive.
- **Ključni koncepti:** API, API točke

U ovom predavanju ćemo proći kroz glavne razlike između ova dva pristupa i dati pregled implikacija koje oni imaju za preuzimanje web sadržaja. Važno je istaknuti da webscraping uključuje ponešto "detektivskog" posla.  Često će biti potrebno prilagoditi korake koje ćemo objasniti na predavanju prema podatcima koje želimo preuzeti, a procedure koje funkcioniraju na jednoj stranici neće nužno funkcionirati i na drugoj (ponekad neće funkcionirati ni na istoj nakon nekog vremena!). Zbog toga se je moguće reći da webscraping podjednako uključuje umjetnost (kreativnost) i znanost (razumijevanje).

Pozitivna strana svega je da server-strana i client-strana dozvoljavaju preuzimanje web sadržaja. Kao što ćemo uskoro vidjeti, preuzimanje podataka sa web stranice koja funkcionira na client-strani (API) je često jednostavnije, pogotovo kada nam je cilj preuzeti veću (*bulk*) količinu podataka. Za webscraping vrijedi općenito pravilo: *ako vidite podatke u browseru, možete ih i preuzeti*.


### Savjet: Etička i zakonska ograničenja

Prethodna rečenica ne uzima u obzir važne etičke i zakonske aspekte preuzimanja sadržaja sa interneta. Samo zato što možete nešto preuzeti sa interneta, ne zanči da biste to i trebali učiniti. Vaša je odgovornost procijeniti da li web stranica polaže zakonska ograničenja na sadržaj koji se tamo nalazi. Alati koje ćemo koristiti u ovom predavanju su uistinu moćni, mogu prenapregnuti server i izazvati poteškoće u radu ili pad web stranice. Glavna maksima kod webscraping-a je stoga "budite pristojni"!


## Webscraping sa **rvest** paketom (server-strana)

Glavni paket u R-u za preuzimanje web sadržaja na strani severa je **rvest** ([link](https://rvest.tidyverse.org/)). To je jednostavan, ali moćan paket za webscraping inspiriran Python-ovom **Beautiful Soup** ([link](https://www.crummy.com/software/BeautifulSoup/)) platformom, ali uz dodatne tidyverse funkcionalnosti :-).  **rvest** je osmišljen za rad sa stranicama koje su procesuirane na strani severa i zbog toga zahtijeva određeno razumijevanje CSS selektora...pa pogledajmo o čemu se radi...

### CSS i SelectorGadget

Za informacije o [CSS](https://developer.mozilla.org/en-US/docs/Learn/CSS/Introduction_to_CSS/How_CSS_works) (i.e Cascading Style Sheets) i [SelectorGadget](http://selectorgadget.com/)-u pročitajte više na interentu. Ukratko, CSS je jezik koji određuje izgled HTML dokumenata (uključujući i web stranice) tako što omogućuje browseru skup pravila za prikaz koja se formiraju na osnovi: 

1. _Properties._ CSS svojstva određuju **kako** će se nešto prkazati. To su npr. fontovi, stilovi, boje, širina stranice itd. 
2. _Selectors._ CSS selektori određuju **što** što će se prikazivati. Oni definiraju pravila koja se pripisuju pojedinim elementima stranice. Npr. tekstualni elementi definirani kao ".h1" (i.e. naslovi) su obično veći i naglašeniji nego elementi definirani kao ".h2" (i.e. podnaslovi).

Za preuzimanje podataka sa web stranice je bitno identificirati CSS selektore sadržaja koji želimo skinuti jer tako izoliramo djelove stranice od interesa. Upravo tu dolazi do izražaja korisnost *SelectorGadget-a*. U ovom predavanju ćemo proći kroz primjer korištenja *SelectorGadget-a*, no preporučljivo je pogledati [vignette](https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html) prije nastavka.

## Praktični primjer: Sprint na 100m (Wikipedia)

Stavimo sve ovo u praktični kontekst kroz preuzimanje podataka sa Wikipedia stranice [**Men's 100 metres world record progression**](http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression). 

Prvo, otvorite ovu stranicu u vašem browser-u. Upoznajte se sa strukturom stranice: Kakve objekte stranica sadrži? Koliko ima tablica? Da li tablice imaju iste kolone? Kakvi su rasponi redova i kolona? itd.

Nakon što ste se upoznali sa strukturom stranice, učitajte cijelu stranicu u R koristeći `rvest::read_html()` funkciju:

```{r m100_read_html}
# library(rvest) ## već učitano
m100 <- read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression") 
# pogledaj objekt 
m100
```

Kao što vidite, ovo je [XML](https://en.wikipedia.org/wiki/XML) dokument^[XML je kratica za Extensible Markup Language i jedan je od glavnih jezika za formatiranje web stranica.] koji sadrži sve potrebno za procesuiranje Wikipedia stranice. To je otprilike kao da promatrate cjeli .pdf dokument (specifikacije, formule, itd.), a želite preuzeti samo jednu tablicu ili dio poglavlja.

### Tablica 1: Pred-IAAF era (1881--1912)

Pokušajmo sada izolirati prvu tablicu sa naslovom [Unofficial progression before the IAAF](https://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression#Unofficial_progression_before_the_IAAF). Kao što je objašnjeno u rvest vignette-i, možemo koristiti funkciju `rvest::html_nodes()` kako bismo izolirali i preuzeli ovu tablicu iz HTML dokumenta kroz specifikaciju odggovarajućih CSS selektora. Potom je potrebno pretvoriti objekt u data.frame koristeći `rvest::html_table()` funkciju. Preporuča se korištenje `fill=TRUE` argumenta u ovom slučaju, jer će se u suprotnom javiti problemi sa formatiranjem redova zbog razmaka u Wiki tablici. 

Koristiti ćemo [SelectorGadget](http://selectorgadget.com/) za identifikaciju CSS selektora. U ovom slučaju je riječ o "div+ .wikitable :nth-child(1)" elementu. Pogledajmo kako to funkcionira:

```{r m100_read_table_e, error=TRUE}
m100 %>%
  html_nodes("div+ .wikitable :nth-child(1)") %>%
  html_table(fill=TRUE) 
```

Izgleda da nešto nije u redu...!? Dobili smo error. Bez da ulazimo u detalje, valja znati da je SelectorGadget ponekad neprecizan....iako je riječ o izvrsnom alatu koji uglavnom radi dobro. Ipak, ponekad ono što izgleda kao dobar selektor (i.e. naglašeno žuto) nije točno ono što tražimo. Ovaj error je namjerno prikazan radi skretanja pažnje na potencijalne probleme koji se mogu javiti pri korištenju SelectorGadget-a. Treba još jednom reći: Webscraping je u jednakoj mjeri umjetnost i znanost!

Na sreću, postoji i precizniji način određivanja točnog selektora, a odnosi se na korištenje "inspect web element" opcije koju ima [većina modernih browser-a](https://www.lifewire.com/get-inspect-element-tool-for-browser-756549). U ovom slučaju koristimo (**Ctrl+Shift+I**, ili desni klik miša i izaberi "Inspect"). Potom ćemo proći kroz *source elemente* dok Chrome ne istakne tablicu koja nas zanima. Nakon toga opet desni klik miša i izaberite **Copy -> Copy selector**. Pogledajte opisanu proceduru:

![](../Foto/inspect100m.gif)

Koristeći ovu metodu dobijemo selektor "#mw-content-text > div > table:nth-child(8)". Pogledajmo da li će ovaj put sve funkcionirati bez error-a. Ponovno ćemo koristiti `rvest::html_table(fill=TRUE)` funkciju za prebacivanje tablice u data.frame:

```{r m100_read_table, dependson=m100, echo=2:5, warning=F, message=F}
m100 <- read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression")
m100 %>%
  html_nodes("table.wikitable:nth-child(9) > tbody:nth-child(1)") %>%
  html_table(fill=TRUE) 

#mw-content-text > div > table:nth-child(8)

```

Sjajno, čini se da sve radi! Sada ćemo sve pripisati novom objektu `pre_iaaf` i još jednom provjeriti objektnu klasu (class).

```{r pre_iaaf_1}
pre_iaaf <-
  m100 %>%
  html_nodes("table.wikitable:nth-child(9) > tbody:nth-child(1)") %>%
  html_table(fill=TRUE) 
class(pre_iaaf)
```

Izgleda da smo uistinu dobili list-u! Pretvorimo sada *stvarno* taj objekt u data.frame. To je moguće učiniti na više načina. U ovom slučaju ćemo koristiti `dplyr::bind_rows()` funkciju. Riječ je o izvrsnom načinu za pretvaranje više list-a u jedan data.frame.^[Ovu funkciju ćemo susresti još nekoliko puta u daljem tijeku kolegija.]

```{r pre_iaaf_2, message = F}
## pretvori list-u u data_frame
# pre_iaaf <- pre_iaaf[[1]] ## također moguće
# library(tidyverse) ## A++već učitano
pre_iaaf <- 
  pre_iaaf %>%
  bind_rows() %>%
  as_tibble()
pre_iaaf
```

Sada je potrebno urediti nazive varijabli (kolona)...ovdje koristimo `janitor::clean_names()` funkciju, koja je napravljena isključivo za tu namjenu. (Q: Na koji još način se to može učiniti?)

```{r pre_iaaf_3}
# library(janitor) ## učitano
pre_iaaf <-
  pre_iaaf %>%
  clean_names()
pre_iaaf
```

<!-- Primijetimo da postoji još "nereda" u zapisima Isaac-a Westergren-a u Gävle, Sweden. Mogli bismo to popraviti na nekoliko načina. U ovom slučaju ćemo pokušati pretvoriti "athlete" varijablu  numeričku i zamijeniti je sa prethodnom vrijednosti. -->

<!-- ```{r pre_iaaf_4} -->
<!-- pre_iaaf <- -->
<!--   pre_iaaf %>% -->
<!--   mutate(athlete = ifelse(is.na(as.numeric(athlete)), athlete, lag(athlete))) -->
<!-- ``` -->

Još je potrebno urediti "date" varijablu tako da R može prepoznati string vrijednosti kao datum.

```{r pre_iaaf_5, message=F}
# library(lubridate) ## već učitano
pre_iaaf <-
  pre_iaaf %>%
  mutate(date = mdy(date))
pre_iaaf
```

Sada imamo čisti data.frame i mogli bismo napraviti vizualizaciju pre-IAAF podataka. Neka to još malo pričeka dok ne preuzmemo ostatak tablica sa stranice...


### Tablica 2: Pred-automatska era (1912--1976)

Nastavimo sada sa sljedećom tablicom:

```{r iaaf_76_1, dependson=m100, echo=1:2}
m100 <- read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression")
iaaf_76 <-
  m100 %>%
  html_nodes("table.wikitable:nth-child(15) > tbody:nth-child(1)") %>%
  html_table(fill=TRUE) 
## Pretvori list-u u data_frame i uredi nazve varijabli (kolona)
iaaf_76 <- 
  iaaf_76 %>%
  bind_rows() %>%
  as_tibble() %>%
  clean_names()
```

Potrebno je popuniti vrijednosti koje nedostaju (NA!) za athlete varijablu (to zahtijeva malo drugačiju proceduru nego u prošloj tablici. Q:Zašto!?) i urediti datume. 

```{r iaaf_76_2, dependson=iaaf_76}
iaaf_76 <-
  iaaf_76 %>%
  mutate(athlete = ifelse(athlete=="", lag(athlete), athlete)) %>%
  mutate(date = mdy(date))
```

Čini se da su neki datumi uvezeni u čudnom zapisu zbog loših podataka (jednaki datumi za različite dane) u tablici:

```{r iaaf_76_3, dependson=iaaf_76}
iaaf_76 %>% tail(20)
```

Problem ćemo riješiti tako da vrijednosti popunimo sa prethohdnim realizacijama (lag-ovima). Isprobajmo za početak:

```{r iaaf_76_4, dependson=iaaf_76}
iaaf_76 %>%
  mutate(date = ifelse(is.na(date), lag(date), date))
```

Izgleda da su datumi postali numerička varijabla (brojevi). Razlog je korištenje base R funkcije `ifelse()` (probajte pronaći na Google-u). U ovom će slučaju biti bolja tidyverse ekvivalentna funkcija, i.e. `if_else()`:

```{r iaaf_76_5, dependson=iaaf_76}
iaaf_76 <-
  iaaf_76 %>%
  mutate(date = if_else(is.na(date), lag(date), date))
iaaf_76
```


### Tablica 3: Moderna era (1977 nadalje)

Zadnja tablica također sadržava neke specifičnosti vezano uz razmake u redovima i ostalo...pa smo ju uredili...bez da ulazimo u detalje oko načina... Probajte sami izvršiti sljedeći kod! Ovdje sve izvršavamo u jednom komadu (*engl. chunk*) koda:

```{r iaaf, dependson=m100, warning=FALSE, message=FALSE}
iaaf <-
  m100 %>%
  html_nodes("table.wikitable:nth-child(20) > tbody:nth-child(1)") %>%
  html_table(fill=TRUE) 
## Pretvori list-u u data_frame i uredi nazve varijabli (kolona)
iaaf <- 
  iaaf %>%
  bind_rows() %>%
  as_tibble() %>%
  clean_names()
## Uredi datum. 
iaaf <-
  iaaf %>%
  mutate(date = mdy(date))
## Usain Bolt  je pripisan Asafa Powell-u zbog
## razmaka u Wikipedia redovima (ista zemlja, i dr.). E.g.
iaaf %>% tail(8)
## Popravljeno
iaaf <-
  iaaf %>%
  mutate(
    athlete = ifelse(athlete==nationality, NA, athlete),
    athlete = ifelse(!is.na(as.numeric(nationality)), NA, athlete),
    athlete = ifelse(nationality=="Usain Bolt", nationality, athlete),
    nationality = ifelse(is.na(athlete), NA, nationality),
    nationality = ifelse(athlete==nationality, NA, nationality)
    ) %>%
  fill(athlete, nationality)
```

### Kombinirane tablice

Povežimo odvojena razdoblja u jedan data.frame. Ponovno ćemo koristiti funkciju `dplyr:: bind_rows()` i zadržati samo zajedničke varijable. Također ćemo dodati varijablu (kolonu) koja se refeira na razdoblje (naziv) za koje su zabilježeni rezultati: 

```{r wr100, dependson=pre_iaaf, dependson=iaaf_76, dependson=iaaf}
wr100 <- 
  bind_rows(
    pre_iaaf %>% select(time, athlete, nationality:date) %>% mutate(era = "IAAF"),
    iaaf_76 %>% select(time, athlete, nationality:date) %>% mutate(era = "Pred-automatska"),
    iaaf %>% select(time, athlete, nationality:date) %>% mutate(era = "Moderna")
  )
wr100
```

Vizualizaciju podataka konačno možemo napraviti na način:

```{r wr100_plot, dependson=wr100, warning=F}
wr100 %>%
  ggplot(aes(x=date, y=time, col=fct_reorder2(era, date, time))) + 
  geom_point(alpha = 0.7) +
  labs(
    title = "Evolucija svjetskog rekorda -- Sprint na 100m",
    x = "Datum", y = "Postignuce (100m u sek)",
    caption = "Izvor: Wikipedia"
    ) +
  theme(legend.title = element_blank()) ## Makni legendu
```


## Sažetak

- Web sadržaj je procesuiran na strani 1) servera ili 2) klijenta.
<br>
- Za preuzimanje sadržaja na strani servera, potrebno je identificirati CSS selektore.
<br>
- Selektore (CSS) možemo identificirati pomoću SelectorGadget-a ili korz *inspekciju* elemenata u browser-u.
<br>
- Koristi se `rvest` paket za učitavanje HTML dokumenta u R i parsanje nodova od interesa.
<br>
  - Tipični pristup rada uključuje:`read_html(URL) %>% html_nodes(CSS_SELECTORS) %>% html_table()`.
<br>
  - Druge funkcije mogu biti potrebne ovisno o vrsti podataka koje preuzimamo (npr. `?html_text`).
<br>
- Samo zato što *možete* preuzeti neku stranicu, ne znači i da *trebate*  (i.e. etički i zakonski aspekti).
<br>
- Webscraping je u jednakoj mjeri umjetnost kao i znanost. Budite spremni na dosta eksperimentiranja i  čišćenja podataka.
<br>
- Nastavak predavanja: Webscraping: (2) Client-strana i API.


## Doddatni resursi i vježba

Probajte koristiti novo-stečene `rvest` vještine na nekom od (mnogih) online tutoriala. Pri tome ne zaboravite:

#### Web manire i bonton

Smomenuli smo princip  "lijepog ponašanja" na web-u...ovdje vrijedi istaknuti **polite** paket ([link](https://github.com/dmi3kno/polite)). Paket omogućava korisne alate u maniri dobrog ponašanja na web-u poput provjere dopuštenja i opterećenja stranice sa koje preuzimamo sadržaj. Paket se također nadopunjuje sa **rvest** pristupom koji smo prikazali u predavanju. 

#### Modeliranje i predviđanje

Preuzeti podatci predstavljaju dobru osnovu za statističku analizu pa ih je dobro promotriti u tom kontekstu. kako biste modelirali napredak u svjetskim sprint rekordima na 100m? Zamislite da želite predvidjeti današnji svjetski rekord u 2005. godini! Kako bi se predviđanje odnosilo na aktualni rekord iz 2009. godine (i.e. Usain Bolt, 9.58 sec)?  Kako biste to interpretirali?

*Savjet: Pogledajte `?broom::tidy()`funkciju za ekstrakciju regresijskih koeficijenata u prikladnom data frame objektu. Već smo vidjeli `geom_smooth()` funkciju u predavanju o vizualizaciji podataka. Za ideje o vizualizaciji predviđanja pogledajte [Poglavlje 23](http://r4ds.had.co.nz/model-basics.html#visualising-models)  R4DS knjige, ili [Poglavlje 6.4](http://socviz.co/modeling.html#generate-predictions-to-graph) SocViz knjige. Razmotrite `base::predict()` funkcij. Alternativno koristite tidyverse's `modelr` paket.*

