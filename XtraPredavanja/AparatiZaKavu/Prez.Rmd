---
title: "<center><div class='mytitle'>Analiza tržišta aparata za kavu</div></center>"
author: "<center><div class='mysubtitle'>Konkurenti: De`Longhi, LatteGo, Krups, Nespresso</div></center>"
date: "<center><div class='mysubtitle'></div></center>"
output:
  html_document:
    theme: yeti
    highlight: espresso
    toc: yes
    toc_depth: 4
    toc_float: yes
    keep_md: yes
    css: style.css
    includes:
      before_body: header.html
      after_body: footer.html
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = FALSE, dpi=300)
```

```{r exc1 , include=F, echo = F,message=F, warning=F }


# Svaka analiza (teksta)  počinje od podataka. Pribava tekstualnih podataka o specifičnim temama najčešće nije jednostavna. Najčešći je način preuzimanja podataka neki od dostupnih API servisa za novinske članke ili tekstualnih repozitorija ili servisi poput Twitter-a. No to često nije dovoljno ukolilko želimo analizirati specifičnu temu ili temu na specifičnom jeziku (npr. hrvatskom). Ovdje još valja napomeniti da je preuzimanje kvalitetnih tekstualnih podataka često moguće isključivo uz nadoplatu kao što je to slučaj člancima na hrvatskom jeziku kroz [webhose.io](https://webhose.io/) servis, [presscliping](https://www.pressclipping.hr/), [presscut](https://www1.presscut.hr/en/) i [mediatoolkit](https://www.mediatoolkit.com/)



```



```{r paketi, echo = F,message=F, warning=F }
library(tidyverse)
library(tidytext)
library(data.table)
library(lubridate)
library(grid)
library(wordcloud)
library(reshape2)
library(igraph)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(DT)
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(scales)
library(tidyverse)
library(httr)
library(lubridate)
library(dplyr)
library(data.table)
library(tidytext)
library(plotly)
library(readxl)
```


```{r podatci, eval=T,message=F, warning=F}
kava <- read_excel("D:/LUKA/Academic/HS/NASTAVA/20-21/WebObradaPodataka/Dta/kava.xlsx") 
```

```{r leksikoni, message=F, warning=F}

## M-Files ----
# function to parse JSON from http conenctiion
parseJSON <- function(x) {
  xCon <- content(x, as = "text", type = "aplication/json", encoding = "UTF-8")
  xCon <- jsonlite::fromJSON(xCon, flatten = TRUE)
  xCon
}
# GET REST API function M-Files
mfiles_get <- function(token, resource){
  req <- GET(url = paste0('http://server.contentio.biz/REST', resource),
             add_headers('X-Authentication' = token, 'content-type' = "application/json"))
  result <- parseJSON(req)
  return(result)
}
# GET token M-Files
req <- POST(url = 'http://server.contentio.biz/REST/server/authenticationtokens.aspx', 
            config = add_headers('content-type' = "application/json"),
            body = list(Username = "msagovac", Password = "Wc8O10TaHz40",
                        VaultGuid = "{7145BCEB-8FE2-4278-AD3B-7AE70374FF8A}",
                        ComputerName  = "CT-VM-01"),
            encode = "json", verbose())
token <- parseJSON(req)[[1]]
# M-FILES DOWNLOAD FILES
mfiles_downlaod <- function(objType, objId, fileId) {
  req <- GET(url = paste0('http://server.contentio.biz/REST/objects/', objType, '/', 
                          objId, '/latest/files/',fileId , '/content'),
             add_headers('X-Authentication' = token))
  reqCon <- content(req, as = "text", encoding = "UTF-8")
  if (is.na(reqCon)) {
    reqCon <- content(req, as = "raw", encoding = "UTF-8")
    reqCon <- rawToChar(reqCon, multiple = FALSE)
    reqCon <- iconv(reqCon, "", "UTF-8")
  }
  reqCon
}
mfiles_downlaod_txt <- function(objType, objId, fileId, ext = ".csv") {
  req <- GET(url = paste0('http://server.contentio.biz/REST/objects/', objType, '/', 
                          objId, '/latest/files/',fileId , '/content'),
             add_headers('X-Authentication' = token))
  reqCon <- httr::content(req)
  tempFileSave <- paste0(tempfile(), ext)
  writeBin(reqCon, tempFileSave)
  return(tempFileSave)
}
# GET classess, props and others
prop <- mfiles_get(token, "/structure/properties")
prop <- prop %>% 
  select(DataType, ID, Name, ObjectType) %>% 
  dplyr::arrange(Name)
objs <- mfiles_get(token, "/structure/objecttypes")
mfilesClass <- mfiles_get(token, "/structure/classes")
CroSentilex_n <- read.delim(mfiles_downlaod_txt("0", 136679, 136711, ext = ".txt"),
                            header = FALSE,
                            sep = " ",
                            stringsAsFactors = FALSE) %>% 
  rename(word = "V1", sentiment = "V2" ) %>%
  mutate(brija = "NEG")
CroSentilex_p <- read.delim(mfiles_downlaod_txt("0", 136681, 136713, ext = ".txt"),
                            header = FALSE,
                            sep = " ",
                            stringsAsFactors = FALSE) %>% 
  rename(word = "V1", sentiment = "V2" ) %>%
  mutate(brija = "POZ")
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
#head(Crosentilex_sve)
CroSentilex_Gold  <- read.delim2(mfiles_downlaod_txt("0", 136680, 136712, ext = ".txt"),
                                 header = FALSE,
                                 sep = " ",
                                 stringsAsFactors = FALSE) %>%
  rename(word = "V1", sentiment = "V2" ) 
CroSentilex_Gold[1,1] <- "dati"
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
#head(CroSentilex_Gold)
# leksikoni
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
my_stop_words <- tibble(
  word = c(
    "jedan","i", "za", "je", "ti","mp","50","4300","5400",
    "e","prvi", "dva","dvije","drugi","u","na","my",
    "tri","tre?i","pet","kod", "bit.ly", "pixie", "https","family.hr","www.elipso.hr", "ea8170", "mp","ti","1","50","5400","4300",
    "ove","ova",  "ovo","bez","hrvatska","momax","možete",
    "evo","oko",  "om", "ek",
    "mil","tko","?est", "sedam",
    "osam",   "?im", "zbog",
    "prema", "dok","zato", "koji", 
    "im", "?ak","me?u", "tek",
    "koliko", "tko","kod","poput", 
    "ba?", "dakle", "osim", "svih", 
    "svoju", "odnosno", "gdje",
    "kojoj", "ovi", "toga","ima","treba","sad","to","kad", "?e","ovaj","?ta","onda","ce","ko"
  ),
  lexicon = "lux"
)
stop_corpus <- my_stop_words %>%
  bind_rows(stopwords_cro)
```



## **Što je unutra?**



- Medijske objave o aparatima za kavu u Hrvatskoj (*LatteGo*, *De`Longhi*, *Krups* i *Nesspreso*)
<br><br>
- Cijeli medijski prostor u Hrvatskoj 
<br><br>
- Razdoblje od 2021-01-09 do 2022-11-01
<br><br>
- Podatci sa [mediatoolkit](https://www.mediatoolkit.com/) servisa
<br><br>
- 290 objava koje sadrže ukupno 8.980 riječi
<br><br>
- Izvještaj uključuje: *pregled medijskog prostora*, *analizu sentimenta*, *analizu sadržaja* i *tematsku analizu*


```{r, message=F, warning=F}

kava %>%
   mutate(kword = case_when(grepl("latteg", MENTION_SNIPPET, ignore.case = TRUE) ~ "LatteGo",
                            grepl("longhi", MENTION_SNIPPET, ignore.case = TRUE) ~ "DeLonghi",
                            grepl("krups", MENTION_SNIPPET, ignore.case = TRUE) ~ "Krups",
                            grepl("Nespresso", MENTION_SNIPPET, ignore.case = TRUE) ~ "Nespresso")) -> kava



```

```{r prilagodi, message=F, warning=F}
# prilagodi podatke
newskava <- kava %>% 
  as.data.frame() %>%
  select(TITLE,MENTION_SNIPPET, DATE, SOURCE_TYPE, AUTHOR, FROM, kword) %>%  
  mutate(datum = as.Date(DATE,"%Y-%m-%d")) %>%
  mutate(clanak = 1:n()) 

```



```{r }

# brzi pregled strukture podataka
#glimpse(newskava)
# izgled podataka
# newskava %>%
#   sample_n(.,10)

#datatable(newskava, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )


```



```{r tokeni}
# tokenizacija

newskava %>% 
  unnest_tokens(word, MENTION_SNIPPET) -> newskava_token 

#newsCOVID_token$word <- stri_encode(newsCOVID_token$word, "", "UTF-8") # prilagodi encoding

#datatable(newskava_token, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

```{r ocisti}
## Ukloni "stop words", brojeve, veznike i pojedinačna slova

newskava_token %>% 
  anti_join(stop_corpus, by = "word") %>%
  mutate(word = gsub("\\d+", NA, word)) %>%
  mutate(word = gsub("^[a-zA-Z]$", NA, word)) %>% 
  drop_na(.)-> newskava_tokenTidy

#datatable(newskava_tokenTidy, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

## **Medijski prostor:**


<br>

- Najvažniji mediji su Web, facebook, instagram i forum
<br><br>
- Nespresso dominira u medijskom prostoru, a DeLonghi slijedi
<br><br>
- Krups i LatteGo zaostaju i na sličnim pozicijama
<br><br>
- Medijske kampanje u dvomjesečnim ciklusima
<br><br>
- Facebook, forum, Instagram imaju jednaku dinamiku
<br><br>
- Brandovi se međusobno prate u medijskom prostoru

<br>
<button class="btn btn-primary" data-toggle="collapse" data-target="#Block6"> Pregled medijskog prostora </button>  
<div id="Block6" class="collapse">

```{r dekriptivnoDom, warning=F,message=F, fig.height=6, fig.width=10}

## Broj domena
# newskava_tokenTidy %>% 
#   summarise(Domena = n_distinct(SOURCE_TYPE))

## Broj objava po domeni

kava %>% 
 # drop_na(.) %>%
  group_by(SOURCE_TYPE) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>% 
  head(20)  %>%
  ggplot(., aes(SOURCE_TYPE,  n, fill = SOURCE_TYPE)) + 
  geom_bar(stat = "identity", show.legend = FALSE) +
  ggtitle("Broj članaka na pojedinom mediju") +
  ylab("Broj članaka") +
  xlab("") 
  theme_economist() 


## Broj objava po brandu

kava %>% 
 # drop_na(.) %>%
  group_by(kword) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>% 
  head(20) %>%
  ggplot(., aes(kword,  n, fill = kword)) + 
  geom_bar(stat = "identity", show.legend = FALSE) +
  ggtitle("Broj članaka o pojedinom brandu") +
  ylab("Broj članaka") +
  xlab("") +
  theme_economist()

## Broj članaka po domeni 

newskava %>% 
   mutate(Datum = floor_date(datum, "week")) %>%
   group_by(Datum, SOURCE_TYPE) %>%
   summarise(n = n()) %>%
   ungroup() %>%
   ggplot(., aes(Datum,  n)) + 
   geom_line() +
   ggtitle("Dinamika objava (mediji)") +
   ylab("Broj članaka") +
   geom_smooth() +
   facet_wrap(~ SOURCE_TYPE, scales = "free_y") +
   theme_economist()
   
## Broj objava kroz vrijeme 

newskava %>% 
   mutate(Datum = floor_date(datum, "week")) %>%
   group_by(Datum, kword) %>%
   summarise(n = n()) %>%
   ungroup() %>%
   ggplot(., aes(Datum,  n)) + 
   geom_line() +
   ggtitle("Dinamika objava (brandovi)") +
   ylab("Broj objavljenih COVID članaka") +
   geom_smooth() +
   facet_wrap(~ kword, scales = "free_y") +
   theme_economist()
     

```

</div>
<br>

- Najčešće riječi su nazivi brandova (Nespresso,DeLonghi i LatteGo)
<br><br>
- Često se spominju i riječi *dom, namještaj, akcije i veliki saloni namještaja*
<br><br>
- Ovo ukazuje na *važnost "mitologije doma"* (manja važnost "mitologije okusa" i/ili "mitologije stila")
<br><br>
- Od prosinca zaoštrena konkurencija između Nespresso, LatteGo i Krups


<br>

<button class="btn btn-primary" data-toggle="collapse" data-target="#Block7"> Najčešće riječi u tekstu </button>  
<div id="Block7" class="collapse">

```{r dekriptivnoTxt, warning=F, message=F, fig.height=10, fig.width=10 }


## Vremenski raspon podatka
#range(newskava_token$DATE)

## Najčešće riječi
# newskava_tokenTidy %>%
#   count(word, sort = T) %>%
#   head(25)

## Vizualizacija najčešćih riječi
newskava_tokenTidy %>%
  count(word, sort = T) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
  theme_economist()

## Vizualizacija najčešćih riječi kroz vrijeme
newskava_tokenTidy %>%
   mutate(Datum = floor_date(datum, "day")) %>%
   group_by(Datum) %>%
   count(word) %>% 
   mutate(gn = sum(n)) %>%
   filter(word %in%  c("nespresso", "de’longhi", "lattego", "krups")) %>%
   ggplot(., aes(Datum,  n / gn)) + 
   geom_point() +
   ggtitle("Medijske kampanje") +
   ylab("% ukupnih riječi") +
   geom_smooth() +
   facet_wrap(~ word, scales = "free_y") +
   scale_y_continuous(labels = scales::percent_format())+
   theme_economist()

```

</div>
<br>

- Općenito **pozitivan sentiment** medijskih objava
<br><br>
- Pozitivan sentiment na osnovi tematike vezane uz **dom, obitelj i kvalitetu života**
<br><br>


<button class="btn btn-primary" data-toggle="collapse" data-target="#Block8"> Najčešće riječi u tekstu </button>  
<div id="Block8" class="collapse">

```{r WCloutSent, warning=F, message=F}

## ComparisonCloud
newskava_tokenTidy %>%
  inner_join(CroSentilex_Gold,by="word") %>% 
  count(word, sentiment) %>% 
  top_n(200) %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
                                 sentiment == 1 ~ "-",
                                 sentiment == 2 ~ "+")) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
                   max.words = 120)


```

</div>
<br>


## **Analiza sentimenta**


- Pozitivan sentiment u periodu pred i za vrijeme blagdana
<br><br>
- Razdoblje za plasman proizvoda na tržište kada je dom u fokusu

<br>
<button class="btn btn-primary" data-toggle="collapse" data-target="#Block9"> Kretanje sentimenta kroz vrijeme </button>  
<div id="Block9" class="collapse">

```{r sentimentTempus, message=F, warning=F, , fig.height=5, fig.width=6}

## Kretanje sentimenta u vremenu 

vizualiziraj_sentiment <- function(dataset, frq = "week") {

dataset %>%
  inner_join( Crosentilex_sve, by = "word") %>%
  filter(!is.na(word)) %>%
  select(word, brija, datum, sentiment) %>% 
  unique() %>%
  spread(. , brija, sentiment) %>%
  mutate(sentiment = POZ - NEG) %>%
  select(word, datum, sentiment) %>% 
  group_by(word) %>% 
  mutate(count = n()) %>%
  arrange(desc(count)) %>%
  mutate( score = sentiment*count) %>%
  ungroup() %>%
  group_by(datum) %>%
  arrange(desc(datum)) -> sm

 
sm %>%
  select(datum, score) %>%
  group_by(Datum = floor_date(datum, frq)) %>%
  summarise(Dnevni_sent = sum(score, na.rm = TRUE)) %>%
  ggplot(., aes(Datum, Dnevni_sent)) +
  geom_bar(stat = "identity") + 
  ggtitle(paste0("Sentiment kroz vrijeme/frekvencija podataka:", frq)) +
  ylab("SentimentScore") +
  theme_economist()-> gg_sentiment_kroz_vrijeme_qv


gg_sentiment_kroz_vrijeme_qv

}

vizualiziraj_sentiment(newskava_tokenTidy,"week")

```

</div>
<br>


- Riječi koje najviše doprinose pozitivnom sentimentu vezane uz **dom**, zdravlje i kvalitetu života
<br><br>
- Važnost nagradnih igara i darivanja


<br>
<button class="btn btn-primary" data-toggle="collapse" data-target="#Block10"> Doprinos sentimentu </button>  
<div id="Block10" class="collapse">

```{r doprinoSentimentu, message=F, warning=F}

## Doprinos sentimentu
doprinos_sentimentu <- function(dataset, no = n) {
dataset %>%
  inner_join(CroSentilex_Gold, by = "word") %>% 
  count(word, sentiment,sort = TRUE) %>% 
  group_by(sentiment) %>%
  top_n(no) %>%
  ungroup() %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "NEUTRALNO",
                                 sentiment == 1 ~ "NEGATIVNO",
                                 sentiment == 2 ~ "POZITIVNO")) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  ggtitle( "Doprinos sentimentu") +
  labs( x = "Riječ", y = "Broj riječi") +
  facet_wrap(~ sentiment, scales = "free_y") +
  coord_flip() +
  theme_economist() -> gg_doprinos_sentimentu
  
 gg_doprinos_sentimentu
 
}


doprinos_sentimentu(newskava_tokenTidy,15)

```

</div>
<br>



- Najbolje plasirane medijske objave ima DeLongi (najveći indeks pozitivnosti)
<br><br>
- Dobra medijska strategija;znatno bolje pozicija od tržišnog lidera Nespresso
<br><br>
- Tržišni lider Nespresso, LatteGo i Krups slični


```{r  include=T, warning=F, message=F}
## Najnegativniji brandovi
wCount <- newskava_tokenTidy %>% 
  group_by(kword) %>%
  summarise(word = n())

CroSentilex_Gold_neg <- CroSentilex_Gold %>% filter(sentiment == 1)
CroSentilex_Gold_poz <- CroSentilex_Gold %>% filter(sentiment == 2)


# newskava_tokenTidy %>% 
#   semi_join(CroSentilex_Gold_neg, by= "word") %>%
#   group_by(kword) %>% 
#   summarise(negWords = n()) %>%
#   left_join(wCount, by = "kword") %>%
#   mutate(negativnostIndex = (negWords/word)*100) %>%
#   arrange(desc(negativnostIndex))

```



<br>
<button class="btn btn-primary" data-toggle="collapse" data-target="#Block12"> Indeks pozitivnosti brandova </button>  
<div id="Block12" class="collapse">

```{r pozDomen, warning=F, message=F}
## Najpozitivniji brandovi

CroSentilex_Gold_poz <- CroSentilex_Gold %>% filter(sentiment == 2)

newskava_tokenTidy %>% 
  semi_join(CroSentilex_Gold_poz, by= "word") %>%
  group_by(kword) %>% 
  summarise(pozWords = n()) %>%
  left_join(wCount, by = "kword") %>%
  mutate(pozitivnostIndex = (pozWords/word)*100) %>%
  arrange(desc(pozitivnostIndex)) %>%
  kbl() %>%
  kable_classic_2()

```

</div>
<br>

```{r eval=F, include=F}

### Veliki portali 

newsCOVID %>%
  group_by(domena) %>%
  count %>%
  arrange(desc(n)) %>%
  head(10) %>%
  pull(domena) -> najveceDomene

newsCOVID %>%
  group_by(domena) %>%
  count %>%
  arrange(desc(n)) %>%
  head(5) %>%
  pull(domena) -> najveceDomene5



newsCOVID_tokenTidy %>% 
  filter(domena %in% najveceDomene) %>%
  semi_join(CroSentilex_Gold_neg, by= "word") %>%
  group_by(domena) %>% 
  summarise(negWords = n()) %>%
  left_join(wCount, by = "domena") %>%
  mutate(negativnostIndex = (negWords/word)*100) %>%
  arrange(desc(negativnostIndex))


newsCOVID_tokenTidy %>% 
  filter(domena %in% najveceDomene) %>%
  semi_join(CroSentilex_Gold_poz, by= "word") %>%
  group_by(domena) %>% 
  summarise(pozWords = n()) %>%
  left_join(wCount, by = "domena") %>%
  mutate(pozitivnostIndex = (pozWords/word)*100) %>%
  arrange(desc(pozitivnostIndex))  

```

## Najvazniji pojmovi

-  **Najbitnije** riječi

- To se radi pomoću [IDF (inverse document frequency)](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.438.2284&rep=rep1&type=pdf) metode 

- IDF metoda omogućuje identifikaciju važnih (ne nužno čestih) riječi u korpusu i može poslužiti za analizu najvažnijih pojmova po brandovima


<br>
<button class="btn btn-primary" data-toggle="collapse" data-target="#Block13"> Pregled najvažnijih riječi za svaki brand </button>  
<div id="Block13" class="collapse">

```{r frekvencija, message=F, warning=F, fig.height=10, fig.width=10}

## Udio riječi po domenama

domenaWords <- newskava %>%
  unnest_tokens(word,MENTION_SNIPPET) %>% 
  count(kword, word, sort = T)
  
ukupnoWords <- domenaWords %>%
  group_by(kword) %>%
  summarise(totWords = sum(n))

domenaWords <- left_join(domenaWords, ukupnoWords)


# domenaWords %>% head(15)

# domenaWords %>% 
# ggplot(., aes(n/totWords, fill = domena)) +
#   geom_histogram(show.legend = FALSE) +
#   xlim(NA, 0.0009) +
#   facet_wrap(~domena, ncol = 2, scales = "free_y")

## Najbitnije riječi po domenma

idf <- domenaWords %>%
  bind_tf_idf(word, kword, n)

#idf %>% head(30)

# idf %>% 
#   select(-totWords) %>%
#   arrange(desc(tf_idf))

idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  mutate(domena = factor(kword)) %>%
  group_by(domena) %>% 
  top_n(10,tf_idf) %>% 
  ungroup() %>%
  ggplot(aes(word, tf_idf, fill = kword)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~kword, scales = "free") +
  coord_flip() +
  theme_economist()


```

</div>
<br>


### nGrami


<br>
<button class="btn btn-primary" data-toggle="collapse" data-target="#Block14"> Pregled najvažnijih bigrama </button>  
<div id="Block14" class="collapse">

```{r nGRAMI, message=F, warning=F, fig.height=10, fig.width=10}


## tokeniziraj na bigram

newskava_bigram <- newskava %>%
  unnest_tokens(bigram, MENTION_SNIPPET, token = "ngrams", n = 2)

## pregledaj podatke

# newskava_bigram %>% head(25)


## najvažniji bigrami

newskava_bigram %>%
  count(bigram, sort = T) %>%
  head(25)

newskava_bigram_sep <- newskava_bigram %>%
  separate(bigram, c("word1","word2"), sep = " ")

newskava_bigram_tidy <- newskava_bigram_sep %>%
  filter(!word1 %in% stop_corpus$word) %>%
  filter(!word2 %in% stop_corpus$word) %>%
  mutate(word1 = gsub("\\d+", NA, word1)) %>%
  mutate(word2 = gsub("\\d+", NA, word2)) %>%
  mutate(word1 = gsub("^[a-zA-Z]$", NA, word1)) %>%
  mutate(word2 = gsub("^[a-zA-Z]$", NA, word2)) %>% 
  drop_na(.)


newskava_bigram_tidy_bigram_counts <- newskava_bigram_tidy %>% 
  count(word1, word2, sort = TRUE)


#newsCOVID_bigram_tidy_bigram_counts

bigrams_united <- newskava_bigram_tidy %>%
  drop_na(.) %>%
  unite(bigram, word1, word2, sep = " ")

#bigrams_united

bigrams_united %>% 
  count(clanak,bigram,sort = T) -> topicBigram

# Najvažniji bigrami po brandovima

 bigram_tf_idf <- bigrams_united %>%
  count(kword, bigram) %>%
  bind_tf_idf(bigram, kword, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  group_by(kword) %>% 
  top_n(7) %>% 
  ungroup() %>%
  ggplot(aes(bigram, tf_idf, fill = kword)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~kword, ncol = 2, scales = "free") +
  coord_flip() + 
  theme_economist()


```

</div>
<br>


```{r vizualizacijaBigrama, eval = F, include = F}

# Analiza bigramskih fraza

newskava_bigram_tidy %>%
  filter(word1 == "kava") %>%
  count(word1,word2,sort=T)

# Vizualiziraj bigrame

bigram_graph <- newskava_bigram_tidy_bigram_counts %>%
  filter(n >50) %>%
   graph_from_data_frame()

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()


```


Povezane riječi:


<br>
<button class="btn btn-primary" data-toggle="collapse" data-target="#Block15"> Pregled korelacije između branda i riječi </button>  
<div id="Block15" class="collapse">

```{r message=F, warning=F, fig.height=10, fig.width=10}
# Korelacije riječi ( R crash na T=30)

#newsCOVID_tokenTidy %>% 
#  filter(published == "2020-04-22") %>%
#  pairwise_count(word, domena, sort = T) %>%
#  filter_all(any_vars(!is.na(.))) -> pairsWords

newskava_tokenTidy %>% 
#  filter(datum > "2020-02-20") %>%
  group_by(word) %>%
  filter(n() > 20) %>%
  filter(!is.na(word)) %>%
  pairwise_cor(word,datum, sort = T) -> corsWords

#corsWords %>%
#  filter(item1 == "oporavak")

corsWords %>%
  filter(item1 %in% c("de’longhi", "krups", "lattego", "nespresso", "dom")) %>%
  group_by(item1) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ item1, scales = "free") +
  coord_flip() + 
  theme_economist()

```

</div>
<br>

## Tematska analiza

- Glavne teme u su: 


<br>
<button class="btn btn-primary" data-toggle="collapse" data-target="#Block16"> Tematska analiza </button>  
<div id="Block16" class="collapse">

```{r TEME, message=F, warning=F, fig.height=10, fig.width=10}

newskava_tokenTidy %>%
  count(clanak, word, sort = TRUE) %>%
  cast_dtm(clanak, word,n) -> dtm

newskava_LDA <- LDA(dtm, k = 4,  control = list(seed = 1234))

newskava_LDA_tidy <- tidy(newskava_LDA, matrix = "beta")
#newsCOVID_LDA_tidy

newskava_terms <- newskava_LDA_tidy %>%
  drop_na(.) %>%
  group_by(topic) %>%
  top_n(15, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

#newsCOVID_terms

newskava_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() + 
  theme_economist()

```

</div>
<br>

- 


<br>
<button class="btn btn-primary" data-toggle="collapse" data-target="#Block17"> Tematska (4) analiza -  bigrami </button>  
<div id="Block17" class="collapse">

```{r TEMEbigram, eval=T, message=F, warning=F,fig.height=10, fig.width=10}

# Bigrami 

topicBigram %>%
  cast_dtm(clanak, bigram,n) -> dtmB

newskava_LDA <- LDA(dtmB, k = 4,  control = list(seed = 1234))

newskava_LDA_tidy <- tidy(newskava_LDA, matrix = "beta")
#newsCOVID_LDA_tidy

newskava_terms <- newskava_LDA_tidy %>%
  drop_na(.) %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

#newsCOVID_terms


newskava_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() + 
  theme_economist()
```

</div>
<br>


## Zaključak


